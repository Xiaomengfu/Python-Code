# Series: single column of data
#create a series
pd.Series(data=list,index=labels)
pd.Series(np.array([1,2,3], labels)
pd.Series(dictionary)

# Series.attribute  .method()
Series.values/.index/.is_unique
Series.get(index/label/list)
Series.count() # exclude Null/NAN/empty value
Series.sum()/.max()/.min()/.mean()
Series.sort_values()
Series.idxmax(): Google.max=Google[Google.idxmax()]
Series.value_counts()
Google.apply(function): Google.apply(lambda p: p+1)

extract by index position: Google[1], Google[1:500], Google[[1,2,3]]

##DataFrames
#create/ input/ output
df=pd.DataFrame(randn(5,4),index='A B C D E'.split(), columns='W X Y Z'.split())
df=pd.read_csv('example',index_col=xxx)
df.to_csv('example',index=False)
pd.read_excel('Excel_Sample.xlsx',sheetname='Sheet1')
df.to_excel('Excel_Sample.xlsx',sheet_name='Sheet1')

df.info()/df.head()/df.tail()
df.sum(axis=0/axis='index'): move across index
df.sum(axis=1/axis='column'): move across columns
#missing data
df.dropna() # default is axis=0
df.dropna(axis=1, inplace=True)
df.dropna(tresh=2)
df['A'].fillna(value=df['A'].mean())

# Selection/Indexing/Extraction
df['name'], df[['name','team']] # extract culomn from df
df.loc['A'] # select rows based on index lable
df.iloc[2] # select across rows by index position
df.loc['index lable', 'column name'] #select subset of rows and columns
df.loc[['A','B'],['W','Y']]

# conditional selection
df[bool value]
df[df['W']>0]
df[df['W']>0]['Y']
df[(df['W']>0) & (df['Y'] > 1)] #For two conditions you can use | and & with parenthesis:

df['new']=df['W']+df['Y'] # create a new column

df.drop('new', axis=1, inplace=Ture) # remove columns
df.drop('E', axis=0) # remove rows

df.rest_index() #reset to default 0,1,...n index
df.set_index('XXX',inplace=True) 

#groupby: group rows of data together and call aggregate functions
df.groupby('company').mean()
df.groupby('company').sum().loc['FB']
df.groupby('company').describe()

pd.concat([df1,df2,df3]) #default is by index, column same, index increase
pd.concat([df1,df2,df3],axis=1) #column increase

pd.merge(left, right, how='inner', in='key')

#Joining is a convenient method for combining the columns of two potentially differently-indexed DataFrames into a single result DataFrame.
left.join(right, how='outer')

df['col2'].unique()
df['col2'].nunique()
df['col2'].value_counts()

df.columns/ df.index
df.sort_values(by='col2', inplace=xxx) #default is inplace= False
df.isnull()

df.to_datetime(xxx) # convert string to datetime

df['Day of Week']=df['Day of Week'].map(dmap) # dmap is a dictionary
unstack() # Pivot a level of the (necessarily hierarchical) index labels, returning a DataFrame having a new level of column labels whose inner-most level consists of the pivoted index labels.

####Pandas Built-in Data Visualization
df1['A'].hist(bins=25, alpha=0.5)
plt.style.use('ggplot') # 'bmh'/'dark_background'/'fivethirtyeight'
df.plot.area
df.plot.barh
df.plot.density
df.plot.hist
df.plot.line # lw (linewidth), ls (linestyle)
df.plot.scatter
df.plot.bar
df.plot.box
df.plot.hexbin
df.plot.kde
df.plot.pie
df.plot(kind='hist') 

df1.plot.scatter(x='A',y='B',c='C', cmap='coolwarm') # use c to color based off another column value

df1.plot.scatter(x='A',y='B',s=df1['C']*200) # use s to indicate size based off another column. s parameter needs to be an array, not just the name of a column

BAC['Close'].ix['2008-01-01':'2009-01-01'].rolling(window=30).mean().plot(label='30 Day Avg') # moving average plot
